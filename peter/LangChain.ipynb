{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "from langchain.agents import create_agent\n",
    "import numpy as np\n",
    "import import_ipynb\n",
    "\n",
    "from functions import *\n",
    "\n",
    "from langchain_ollama import ChatOllama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we define all the tools or \"functions\" that our agent will have access to \n",
    "\n",
    "@tool\n",
    "def func1(x: float, y: float) -> float:\n",
    "    \"\"\"multiply two numbers.\"\"\"\n",
    "    return x*y#np.round(x * y, 5)\n",
    "\n",
    "@tool\n",
    "def func2(x: float, y: float) -> float:\n",
    "    \"\"\"add two numbers.\"\"\"\n",
    "    return x+y#np.round(x + y, 5)\n",
    "\n",
    "@tool\n",
    "def generate_el_su2():\n",
    "    \"\"\"doc string\"\"\"\n",
    "    theta1 = (np.pi/2)*np.random.rand()\n",
    "    phi1, phi2 = 2*np.pi*np.random.rand(2)\n",
    "    return np.matrix([[np.exp(1j*phi1)*np.cos(theta1),\\\n",
    "                      -np.exp(-1j*phi2)*np.sin(theta1)],\\\n",
    "                     [np.exp(1j*phi2)*np.sin(theta1),\\\n",
    "                      np.exp(-1j*phi1)*np.cos(theta1)]])\n",
    "\n",
    "tools = [func1]\n",
    "#tools = [func2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the LLM model our Agent will use for the conversations and reasoning part\n",
    "# We are using a simple ollama model but we can use GPT-SSO with Fermilab resources\n",
    "\n",
    "model = ChatOllama(model=\"llama3.1\", temperature=0.1) # temperature is how creative the model is (low is less creative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we build our agent and feed the model, the tools the description or prupose of the model, memory etc\n",
    "# https://reference.langchain.com/python/langchain/agents/#langchain.agents.create_agent(checkpointer)\n",
    "\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=tools,\n",
    "    #system_prompt=\"You use generate_el_su2 to generate an element of the special unitary group of dimension 2.\", # shape how your agent approaches tasks\n",
    "    system_prompt=\"use func1 to multiply 2 input numbers.\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Here is where we call the agent and tell it the user is asking...\n",
    "\n",
    "response = agent.invoke({\"messages\":[{\n",
    "                'role': 'user', 'content': '\"Multiply 753 and 9256\"'\n",
    "                }]\n",
    "                })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The result of multiplying 753 and 9256 is 6969768.\n"
     ]
    }
   ],
   "source": [
    "#print(response)\n",
    "print(response['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6969768"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "753*9256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='\"Give me an element of SU(2) as a numpy matrix.\"', additional_kwargs={}, response_metadata={}, id='6d5c1e55-5b1f-4d85-b2bb-503807f801d1'), AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'llama3.1', 'created_at': '2026-01-13T20:54:01.140868509Z', 'done': True, 'done_reason': 'stop', 'total_duration': 13687253189, 'load_duration': 199147563, 'prompt_eval_count': 176, 'prompt_eval_duration': 10286415244, 'eval_count': 15, 'eval_duration': 3165981920, 'logprobs': None, 'model_name': 'llama3.1', 'model_provider': 'ollama'}, id='lc_run--019bb922-d93c-7b41-88c7-da27bb495d84-0', tool_calls=[{'name': 'generate_el_su2', 'args': {}, 'id': 'ba6afde7-c250-4312-8f83-28370b1d7249', 'type': 'tool_call'}], usage_metadata={'input_tokens': 176, 'output_tokens': 15, 'total_tokens': 191}), ToolMessage(content='[[-0.35836829+0.9161037j  -0.15530158+0.09059577j]\\n [ 0.15530158+0.09059577j -0.35836829-0.9161037j ]]', name='generate_el_su2', id='d6ff7613-47a0-46af-a1d1-a617485926ec', tool_call_id='ba6afde7-c250-4312-8f83-28370b1d7249'), AIMessage(content='This is an element of the special unitary group SU(2) as a numpy matrix.', additional_kwargs={}, response_metadata={'model': 'llama3.1', 'created_at': '2026-01-13T20:54:16.687485353Z', 'done': True, 'done_reason': 'stop', 'total_duration': 15540757369, 'load_duration': 154588844, 'prompt_eval_count': 175, 'prompt_eval_duration': 10792466718, 'eval_count': 20, 'eval_duration': 4550010534, 'logprobs': None, 'model_name': 'llama3.1', 'model_provider': 'ollama'}, id='lc_run--019bb923-0eb9-7ec0-a0f3-d44cc6d6ba4f-0', usage_metadata={'input_tokens': 175, 'output_tokens': 20, 'total_tokens': 195})]}\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[[-0.35836829+0.9161037j  -0.15530158+0.09059577j]\\n [ 0.15530158+0.09059577j -0.35836829-0.9161037j ]]'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['messages'][2].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_mat = np.matrix([[ 0.35203076-0.7565501j,  -0.0829075 -0.54482349j], [ 0.0829075 -0.54482349j,  0.35203076+0.7565501j ]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[9.99999999e-01+0.j, 2.94888397e-19+0.j],\n",
       "        [2.94888397e-19+0.j, 9.99999999e-01+0.j]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_mat.H @ my_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.complex128(0.9999999986082178+0j)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.det(my_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='\"What is pi times Euler\\'s number rounded to 12 digits after the decimal?\"', additional_kwargs={}, response_metadata={}, id='8e117cdd-fa00-4e65-ba30-24d99d3547a8'), AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'llama3.1', 'created_at': '2026-01-13T20:33:20.842212985Z', 'done': True, 'done_reason': 'stop', 'total_duration': 50552351801, 'load_duration': 16989616100, 'prompt_eval_count': 236, 'prompt_eval_duration': 25789542818, 'eval_count': 33, 'eval_duration': 7678977645, 'logprobs': None, 'model_name': 'llama3.1', 'model_provider': 'ollama'}, id='lc_run--019bb90f-5aac-7373-b31c-ec246c7ce116-0', tool_calls=[{'name': 'func1', 'args': {'x': 3.14159265359, 'y': 2.71828182846}, 'id': '9eed0e22-34c9-42d5-845d-0aabed36c905', 'type': 'tool_call'}], usage_metadata={'input_tokens': 236, 'output_tokens': 33, 'total_tokens': 269}), ToolMessage(content='8.539734222677128', name='func1', id='d4374535-d045-4a46-93e0-beb9acf10d21', tool_call_id='9eed0e22-34c9-42d5-845d-0aabed36c905'), AIMessage(content=\"The result of pi times Euler's number rounded to 12 digits after the decimal is 8.539734223.\", additional_kwargs={}, response_metadata={'model': 'llama3.1', 'created_at': '2026-01-13T20:33:34.050740337Z', 'done': True, 'done_reason': 'stop', 'total_duration': 13194131910, 'load_duration': 183766758, 'prompt_eval_count': 137, 'prompt_eval_duration': 7028900481, 'eval_count': 25, 'eval_duration': 5919195115, 'logprobs': None, 'model_name': 'llama3.1', 'model_provider': 'ollama'}, id='lc_run--019bb910-21d7-7a52-93af-52d4e939d057-0', usage_metadata={'input_tokens': 137, 'output_tokens': 25, 'total_tokens': 162})]\n"
     ]
    }
   ],
   "source": [
    "for key, val in response.items():\n",
    "    print(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__abstractmethods__',\n",
       " '__add__',\n",
       " '__annotations__',\n",
       " '__class__',\n",
       " '__class_getitem__',\n",
       " '__class_vars__',\n",
       " '__copy__',\n",
       " '__deepcopy__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__fields__',\n",
       " '__fields_set__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__get_pydantic_core_schema__',\n",
       " '__get_pydantic_json_schema__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__pretty__',\n",
       " '__private_attributes__',\n",
       " '__pydantic_complete__',\n",
       " '__pydantic_core_schema__',\n",
       " '__pydantic_custom_init__',\n",
       " '__pydantic_decorators__',\n",
       " '__pydantic_extra__',\n",
       " '__pydantic_fields_set__',\n",
       " '__pydantic_generic_metadata__',\n",
       " '__pydantic_init_subclass__',\n",
       " '__pydantic_parent_namespace__',\n",
       " '__pydantic_post_init__',\n",
       " '__pydantic_private__',\n",
       " '__pydantic_root_model__',\n",
       " '__pydantic_serializer__',\n",
       " '__pydantic_validator__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__repr_args__',\n",
       " '__repr_name__',\n",
       " '__repr_str__',\n",
       " '__rich_repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__signature__',\n",
       " '__sizeof__',\n",
       " '__slots__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_abc_impl',\n",
       " '_calculate_keys',\n",
       " '_check_frozen',\n",
       " '_copy_and_set_values',\n",
       " '_get_value',\n",
       " '_iter',\n",
       " 'additional_kwargs',\n",
       " 'artifact',\n",
       " 'coerce_args',\n",
       " 'construct',\n",
       " 'content',\n",
       " 'content_blocks',\n",
       " 'copy',\n",
       " 'dict',\n",
       " 'from_orm',\n",
       " 'get_lc_namespace',\n",
       " 'id',\n",
       " 'is_lc_serializable',\n",
       " 'json',\n",
       " 'lc_attributes',\n",
       " 'lc_id',\n",
       " 'lc_secrets',\n",
       " 'model_computed_fields',\n",
       " 'model_config',\n",
       " 'model_construct',\n",
       " 'model_copy',\n",
       " 'model_dump',\n",
       " 'model_dump_json',\n",
       " 'model_extra',\n",
       " 'model_fields',\n",
       " 'model_fields_set',\n",
       " 'model_json_schema',\n",
       " 'model_parametrized_name',\n",
       " 'model_post_init',\n",
       " 'model_rebuild',\n",
       " 'model_validate',\n",
       " 'model_validate_json',\n",
       " 'model_validate_strings',\n",
       " 'name',\n",
       " 'parse_file',\n",
       " 'parse_obj',\n",
       " 'parse_raw',\n",
       " 'pretty_print',\n",
       " 'pretty_repr',\n",
       " 'response_metadata',\n",
       " 'schema',\n",
       " 'schema_json',\n",
       " 'status',\n",
       " 'text',\n",
       " 'to_json',\n",
       " 'to_json_not_implemented',\n",
       " 'tool_call_id',\n",
       " 'type',\n",
       " 'update_forward_refs',\n",
       " 'validate']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(response['messages'][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: func1\n",
      "\n",
      "8.539734222677128\n"
     ]
    }
   ],
   "source": [
    "response['messages'][2].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(response['messages'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
